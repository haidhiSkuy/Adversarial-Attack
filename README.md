# Adversarial Attack
Adversarial attack is techniques to fool machine learning model. I try two methods: FGSM and one-pixel attack. I use fruit classification model with 98%> accuracy. The attack methods is damn effective
